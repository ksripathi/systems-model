#+TITLE: Private DNS
#+PROPERTY: session *scratch*
#+PROPERTY: results output
#+PROPERTY: exports code
#+SETUPFILE: org-templates/level-0.org
#+OPTIONS: ^nil

* Introduction
  This document describes the requirements, design and implementation
  of the private *Domain Name System (DNS)*.  This server provides the
  domain name resolution for all other servers in the cluster.  This
  server resolves both the private zones (vlabs.ac.in and
  virtual-labs.ac.in) and the external zones (eg. gnu.org, google.com)
  for all other servers.

  Generally a DNS is configured in a master-slave replication
  topology.  In such a configuration, if any changes are performed on
  the master, then such changes are automatically replicated to the
  slave.  Thus the master-slave replication allows for having
  redundant servers without requiring the administrators to manually
  keep multiple DNS servers synchronized.  This redundancy is useful
  when the master machine fails (eg power failure, network failure)
  as, then the slave can handle all the queries without affecting the
  service up-time.

  In our architecture we have avoided the master-slave replication.
  This is possible because all the changes are performed using the
  ansible scripts.  These scripts modify all the DNS servers in the
  same way.  These scripts prevent human errors and do not require an
  additional effort in keeping multiple nodes synchronized.

  Further redundancy using multiple DNS servers has been avoided
  altogether.  This is because if a DNS server fails,
  then a new DNS server can be configured quickly using existing
  ansible scripts.  

* Requirements
  The functional and security requirements of the private DNS are
  mentioned in the following sections.  Only the DNS specific
  requirements which differ from the generic requirements (specified
  in the [[common%20role][common role]] ) are mentioned here.

** Functional Requirements
   The Private DNS should resolve authoritative zones
   (vlabs.ac.in. and virtual-labs.ac.in.) for all the internal
   clients.  Private DNS should accept DNS queries on default UDP port
   53 from all internal clients.  It should also resolve all domain
   names for internal clients (Peer DNS) recursively.

** Security Requirements
   All the common security requirements as described in the common
   role are applicable to the private DNS.  Along with them UDP port
   53 should be allowed only from machines in the cluster.

** Communication Requirements
   The private DNS requires router for access to the Internet.  This
   internet access is used for recursive DNS lookups.  This is also
   useful while updating packages using public package repositories.

* Design
** Private DNS communication diagram
   The following network diagram represents the interaction between
   the private DNS and all other machines in the cluster.  This
   diagram primarily focuses on the functionality of the DNS server.

#+CAPTION:  Private DNS Network Diagram
#+LABEL:  fig-private-dns-diagram
[[./diagrams/private-dns-network-diagram.png]]

** Important configuration and data files and folders 
   The following table gives the information about the configuration
   files which may need to be modified to setup a DNS server using
   =bind= package.
# Private DNS
   |------+----------+-------------------------------+----------------------------------|
   | S.no | Service  | File                          | Description                      |
   |------+----------+-------------------------------+----------------------------------|
   |    1 | named    | /etc/named.conf               | Main configuration file for      |
   |      |          |                               | bind DNS server                  |
   |------+----------+-------------------------------+----------------------------------|
   |    2 | named    | /var/named/<domain_name>.zone | Zone files for specifying        |
   |      |          |                               | authorized zone resource records |
   |------+----------+-------------------------------+----------------------------------|
   |    3 | iptables | /etc/sysconfig/iptables       | iptables firewall start-up rules |
   |------+----------+-------------------------------+----------------------------------|
   |    4 | named    | /etc/sysconfig/named          | This file is modified to disable |
   |      |          |                               | IPv6 support                     |
   |------+----------+-------------------------------+----------------------------------|
   
* Implementation
** Structure of the scripts
   The implementation of this system is in terms of a collection of
   Ansible scripts that configure the node.  These scripts are
   organized as follows:

#+BEGIN_EXAMPLE
|-code
|   |-- private_dns.yml
|   |-- roles
|   |   |-- named_server
|   |   |   |-- handlers
|   |   |   |   `-- main.yaml
|   |   |   |-- tasks
|   |   |   |   `-- main.yaml
|   |   |   `-- templates
|   |   |   |   |-- named.conf
|   |   |   |   |-- named_iptables
|   |   |   |   `-- zone.forward

#+END_EXAMPLE
  
   Here =private_dns.yaml= file configures the private DNS with the
   "named_server" and "common" roles as described in the [[Creating%20the%20Private%20DNS][Creating the
   Private DNS]] section.  The =roles/named_server/handlers/main.yaml=
   file defines various handlers which are only executed in case a task
   notifies them.  These handlers are described in detail in the
   [[Handlers]] section.  The handlers are called when the tasks described
   in the [[Tasks][Tasks]] section notify them.  Various tasks of [[Tasks][Tasks]] section
   are concatenated into =roles/named_server/tasks/main.yaml= file.
   The =roles/named-server/templates/= folder contains three jinja2
   configuration templates - =named_iptables=, =zone.forward=,
   =named.conf=.  These templates use variables defined at various
   places to configure the DNS server with appropriate values.

** Building the firewall rules
   The firewall rules have to be configured. This is done by writing
   down the rules in a template. This template is later used as
   described in the [[Apply%20the%20firewall%20rules][Apply the firewall rules]] section.  The template
   below contains the generic firewall rules also. These are described
   in detail in the [[./common.org][common role]].  The rules which are specific to the
   private DNS are also mentioned here in this template.

#+BEGIN_SRC YAML -n :tangle roles/named_server/templates/named_iptables
*filter
:INPUT ACCEPT [-1:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
#Accept loopback connections
-A INPUT -i lo -d 127.0.0.0/8 -j ACCEPT
#Rate limit new connections to 20 new connections per 30 seconds
-A INPUT ! -p udp -m state --state NEW -m recent --name new_limit --set
-A INPUT ! -p udp -m state --state NEW -m recent --name new_limit --rcheck --seconds 30 --hitcount 20 -m limit --limit 2/min -j LOG --log-prefix "new_limit_"
-A INPUT ! -p udp -m state --state NEW -m recent --name ssh_limit --rcheck --seconds 30 --hitcount 20 -j DROP
#Accept ICMP ping requests at limited rate
-A INPUT -p icmp --icmp-type echo-request -m limit --limit 60/minute --limit-burst 120 -j ACCEPT
-A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/minute --limit-burst 2 -j LOG
-A INPUT -p icmp --icmp-type echo-request -j DROP
#Allow ongoing connections
-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
#Allow incoming SSH connections from management IPs.  Hopefully fail2ban will take care of bruteforce attacks from management IPs
{% for item in management_ips  %}
-A INPUT -m state --state NEW -s {{item}} -p tcp -m tcp --dport 22 -j ACCEPT
{% endfor %}
#Allow incoming SSH connections from ansible server IPs.  Hopefully fail2ban will take care of bruteforce attacks from ansible server IPs
{% for item in ansible_server_ips  %}
-A INPUT -m state --state NEW -s {{item}} -p tcp -m tcp --dport 22 -j ACCEPT
{% endfor %}
#Allow incoming SSH connections from rsnapshot server IPs.
{% for item in rsnapshot_server_ips  %}
-A INPUT -m state --state NEW -s {{item}} -p tcp -m tcp --dport 22 -j ACCEPT
{% endfor %}
#Allow incoming SSH connections from nagios server IPs.  
{% for item in nagios_server_ips  %}
-A INPUT -m state --state NEW -s {{item}} -p tcp -m tcp --dport 22 -j ACCEPT
{% endfor %}
#Allow access to DNS from everywhere.  The allow_query option in DNS will take care of limiting clients. 
-A INPUT -m state --state NEW -p udp -m udp --dport 53 -j ACCEPT
#Allow incoming NRPE queries for nagios from nagios servers
-A INPUT -m state --state NEW -p tcp -m tcp --dport 5666 -j ACCEPT
#Allow SNMP queries from cacti servers
#-A INPUT -p udp -m udp --dport 161 -j ACCEPT
#-A INPUT -p udp -m udp --dport 162 -j ACCEPT
#Log all other "blocked_input_" attempts with rate limiting
-A INPUT -m state --state NEW -m limit --limit 2/min -j LOG --log-prefix "blocked_input_"
#Reply with proper ICMP error message and reject the connection
-A INPUT -j REJECT --reject-with icmp-host-prohibited
#Disable packet forwarding through firewall
-A FORWARD -j REJECT --reject-with icmp-host-prohibited
#
#
##Output rules
#Allow outgoing connections to localhost
-A OUTPUT -s 127.0.0.0/8 -o lo -j ACCEPT
#Allow outgoing replies to ansible from SSH server
{% for item in ansible_server_ips  %}
-A OUTPUT -d {{item}} -p tcp -m tcp --sport 22 -j ACCEPT
{% endfor %}
#Allow ongoing connections
-A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
#Allow DNS queries
-A OUTPUT -p udp -m udp --dport 53 -j ACCEPT
#Allow server to send emails.  Required for sending logwatch emails
-A OUTPUT -p tcp -m tcp --dport 25 -j ACCEPT
#Allow server to contact web-servers.  Required for yum update and installation
#For restrictive configurations this can be disabled after install
-A OUTPUT -p tcp -m tcp --dport 80 -j ACCEPT
-A OUTPUT -p tcp -m tcp --dport 443 -j ACCEPT
#Allow outgoing connections to rsyslog server
-A OUTPUT -p udp -m udp --dport 514 -j ACCEPT
#Allow outgoing connections to OSSEC server
-A OUTPUT -p udp -m udp --dport 1514 -j ACCEPT
#Allow outgoing ping requests
-A OUTPUT -p icmp --icmp-type echo-request -j ACCEPT
#Log all other "blocked_output_" attempts
-A OUTPUT -m state --state NEW -m limit --limit 2/min -j LOG --log-prefix "blocked_output_"
#Reply with proper ICMP error message and reject the connection
-A OUTPUT -j REJECT --reject-with icmp-host-prohibited
COMMIT
#
#+END_SRC

   Generally the other nodes are just allowed to send DNS
   queries. These queries are answered by the private DNS. The private
   DNS should be able to allow the incoming DNS queries on
   port 53. The =INPUT= table has a rule which specifies this access.
   
** Tasks
*** Installing the bind service
    To configure the node as a DNS server the *bind* package has to be
    installed.  We are currently using
    /bind-9.8.2-0.30.rc1.el6_6.2.x86_64/ package. Another
    package *bind-utils* is also installed to help administrators in
    debugging / validating DNS configuration by sending custom queries
    to required DNS servers. This is done by the following code:

#+BEGIN_SRC YAML :tangle roles/named_server/tasks/main.yaml
---
- name: Install bind and bind-utils package
  yum: name="{{item}}" state=present
  with_items:
    - bind
    - bind-utils
#+END_SRC

*** Configuring the Bind service
    The installed bind service has to be configured to serve as the
    private DNS. This configuration is done in the file named
    =/etc/named.conf=.  We specify the domain for which this server
    should be the authoritative DNS. These are termed as zones in the
    configuration file.  This is described in detail in the section
    [[Creating%20the%20zone%20files][Creating the zone files]].  We configure the
    =/roles/named_server/templates/named.conf= template with these
    configurations. The template is as follows:

#+BEGIN_SRC YAML :tangle roles/named_server/templates/named.conf
//
// named.conf
//
// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS
// server as a caching only nameserver (as a localhost DNS resolver only).
//
// See /usr/share/doc/bind*/sample/ for example named configuration files.
//

options {
        listen-on port 53 { 127.0.0.1; any; };
        listen-on-v6 port 53 { ::1; };
        directory       "/var/named";
        dump-file       "/var/named/data/cache_dump.db";
        statistics-file "/var/named/data/named_stats.txt";
        memstatistics-file "/var/named/data/named_mem_stats.txt";
        allow-query     { localhost; {{allow_query_from}} };
        recursion {{recursion}};

        dnssec-enable no;
        dnssec-validation no;
        dnssec-lookaside auto;

        /* Path to ISC DLV key */
        bindkeys-file "/etc/named.iscdlv.key";

        managed-keys-directory "/var/named/dynamic";
};

logging {
        channel default_debug {
                file "data/named.run";
                severity dynamic;
        };
};
{% if is_amazon == "yes" %}
{% for item in zone_names %}
zone "{{item}}" IN {
   type master;
   file "{{item}}forward";
};
{% endfor %}
{% else %}

{% for item in zone_names %}
zone "{{item}}" IN {
   type master;
   file "{{item}}forward";
};
{% endfor %}
zone "vlabs.ac.in." IN {
      type forward;
      forwarders {{forwarders}};
};

{% endif %}

zone "." IN {
        type hint;
        file "named.ca";
};

include "/etc/named.rfc1912.zones";
include "/etc/named.root.key";
#+END_SRC    
    
    This template should be placed in the correct location on the
    node.  This is done by the following code:

#+BEGIN_SRC YAML :tangle roles/named_server/tasks/main.yaml
- name: Create custom named.conf with desired zone
  template: src=named.conf dest=/etc/named.conf owner=root group=named mode=640
  notify:
    - restart bind
#+END_SRC

    Once this is configured the task notifies the handler. This is
    further described in the [[Handlers]] section.

*** Creating the zone files
    Each zone (domain) is associated with a zone file which contains a
    list of all the sub-domains under that domain and also their
    corresponding IP address to which the request for that FQDN should
    be sent to. Here we create one zone file each for the domains
    "virtual-labs.ac.in" and "vlab.ac.in".  The zone file template
    =/roles/named_server/templates/zone.forward= looks like the
    following:

#+BEGIN_SRC YAML :tangle roles/named_server/templates/zone.forward
$TTL 3600
@ SOA ns.{{item}} root.{{item}} (1 15m 5m 30d 1h)
                IN      NS      {{name_server}}
                IN      A       {{zone_address}}

                MX      10 ASPMX.L.GOOGLE.COM.
                MX      20 ALT1.ASPMX.L.GOOGLE.COM.
                MX      20 ALT2.ASPMX.L.GOOGLE.COM.
                MX      30 ASPMX2.GOOGLEMAIL.COM.
                MX      30 ASPMX3.GOOGLEMAIL.COM.

{% for server1 in servers %}

{{server1.hostname}}    IN      A       {{server1.ip}}

{% endfor %}
#+END_SRC
    
    The above template should be placed in the correct location on the
    node. This is done by the following code:

#+BEGIN_SRC YAML :tangle roles/named_server/tasks/main.yaml
- name: Copy zone forward files for all zones to /var/named
  template: src="zone.forward" dest="/var/named/{{item}}forward" owner=root group=named mode=640
  with_items: zone_names
  notify:
    - restart bind
#+END_SRC

*** Some more configuration
    Disabling the IPv6 support. 

#+BEGIN_SRC  YAML :tangle roles/named_server/tasks/main.yaml
- name: Disable IPv6 support
  lineinfile: dest=/etc/sysconfig/named line='OPTIONS="-4"' regexp="^OPTIONS"
  notify:
    - restart bind
#+END_SRC

*** Bringing up the Bind service
    After configuring the required configuration files in the above
    sections, the service needs to be restarted.

#+BEGIN_SRC YAML :tangle roles/named_server/tasks/main.yaml
- name: Start and enable bind service
  service: name=named state=started enabled=yes
#+END_SRC

*** Apply the firewall rules
    The firewall rules which were written in a template, need to be
    configured by placing them in their specific location. This is
    done from the following script.

#+BEGIN_SRC YAML :tangle roles/named_server/tasks/main.yaml
- name: Configure strong firewall on bind/named server
  template: src=named_iptables dest=/etc/sysconfig/iptables
  notify:
    - restart iptables
#+END_SRC

** Handlers
   The services should be restarted if there are any changes made to
   the configuration file. This is taken care of by the following
   code.

#+BEGIN_SRC YAML :tangle roles/named_server/handlers/main.yaml
---
- name: restart bind
  service: name=named state=restarted

- name: restart iptables
  service: name=iptables state=restarted
#+END_SRC
** Creating the Private DNS
   All the steps mentioned above in the [[Tasks]] and [[Handlers]] sections
   need to be implemented. This is done by the script below, which
   calls all the steps above in the required sequence.
#+BEGIN_SRC YAML :tangle private_dns.yaml 
---
- name: This file configures private dns server
  hosts: private_dns
  remote_user: root

  vars:
    host_name: "private-dns.{{prefix}}vlabs.ac.in"
    zone_file_prefix: private.
    zone_names:
      - "{{prefix}}virtual-labs.ac.in."
      - "{{prefix}}vlabs.ac.in."
    zone_address: 10.100.2.101
    allow_query_from: "10.0.0.0/8; 172.16.0.0/12; 192.168.0.0/16;"
    name_server: private-dns
    recursion: yes
    servers: "{{private_dns_entries}}"
  roles:
    - common
    - rsyslog_client
    - ossec_client
    - nagios_client
    - rsnapshot_client
    - named_server

#+END_SRC
   
* Test Cases
** Test case ID: TC01
*** Objective
    The objective is to test the working of the name server to resolve
    the hostnames of other machines which have been configured in the
    Private DNS zone file.
*** Apparatus
    - The Private DNS container/machine
    - Another machine in the same network
*** Theory
    The named server contains a list of hostnames with their
    corresponding IP addresses. Once the service is running it is
    capable of resolving these hostnames to their respective IP
    addresses. There are command-line tools available which help in
    querying the DNS server. For our test case we use =nslookup= and
    =dig=. Both of them are command-line tools which query the
    DNS. Since this test is being done by the systems engineer, he
    would know the configured IP addresses of the hostnames. This
    helps in knowing if the result of the query is right or wrong.
*** Procedure
    - First we take a another machine in the same network as that of
      the name-server.
    - Now we need to install the command-line tools we need to do the
      following: for a ubuntu machine
      #+BEGIN_EXAMPLE
      sudo apt-get install bind-utils
      #+END_EXAMPLE
      or (for a centos machine)
      #+BEGIN_EXAMPLE
      sudo yum install bind-utils
      #+END_EXAMPLE
    - Now we need to set the name server of this machine to be the
      Private DNS machine that we just configured. For this we need to
      edit the file =/etc/resolv.conf=. The content of the file should
      be as below:
      #+BEGIN_EXAMPLE
      nameserver <IP of the Private DNS>
      #+END_EXAMPLE
    - Now on this machine we need to run the command-line tool to
      query the DNS server. These tools might not be installed on all
      machines by default, so we need to install them.
    - Now we run the tools as follows:
      #+BEGIN_EXAMPLE
      dig <FQDN>
      #+END_EXAMPLE
    - We can also use the nslookup tool.
      #+BEGIN_EXAMPLE
      nslookup <FQDN>
      #+END_EXAMPLE
    - By running these commands we can determine if the DNS is
      resolving the names properly or not.

*** Experiments
    We need to perform testing by using the command line tools. In the
    terminal of the other machine do the following:
    #+BEGIN_EXAMPLE
    nslookup ossec-server.base1.virtual-labs.ac.in
    #+END_EXAMPLE
    and 
    #+BEGIN_EXAMPLE
    dig ossec-server.base1.virtual-labs.ac.in
    #+END_EXAMPLE
*** Result
    - The result obtained from the first command is as below : 
    #+BEGIN_EXAMPLE
    Server:		10.100.1.5
    Address:	10.100.1.5#53

    Name:	ossec-server.base1.virtual-labs.ac.in
    Address: 10.100.1.3
    #+END_EXAMPLE
    - The result obtained from the second command is as below:
    #+BEGIN_EXAMPLE
    ; <<>> DiG 9.8.2rc1-RedHat-9.8.2-0.30.rc1.el6_6.2 <<>> ossec-server.base1.virtual-labs.ac.in
    ;; global options: +cmd
    ;; Got answer:
    ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 9080
    ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 1

    ;; QUESTION SECTION:
    ;ossec-server.base1.virtual-labs.ac.in. IN A

    ;; ANSWER SECTION:
    ossec-server.base1.virtual-labs.ac.in. 3600 IN A 10.100.1.3

    ;; AUTHORITY SECTION:
    base1.virtual-labs.ac.in. 3600	IN	NS	private-dns.base1.virtual-labs.ac.in.

    ;; ADDITIONAL SECTION:
    private-dns.base1.virtual-labs.ac.in. 3600 IN A	10.100.1.5

    ;; Query time: 0 msec
    ;; SERVER: 10.100.1.5#53(10.100.1.5)
    ;; WHEN: Mon Apr  6 05:57:26 2015
    ;; MSG SIZE  rcvd: 113
    #+END_EXAMPLE

*** Observation
    From the results obtained above it can be observed that both the
    queries give the output of the query made to the DNS server. The
    output of dig queries are generally more descriptive and detailed
    than nslookup. The crux of both of these command line tools is to
    determine if the query for a particular FQDN gave the
    corresponding IP of that machine to which the domain name belongs,
    which both do.  The given FQDN was
    =ossec-server.base1.virtual-labs.ac.in=. The obtained result
    showed that this FQDN belonged to a machine with IP =10.100.1.3=.
    This shows that the Private DNS was able to resolve the hostname
    of the server to its corresponding IP address. The same IP was
    configured against this hostname in the Private DNS.

*** Conclusion
    The Private DNS is resolving the hostnames correctly.

** Test case ID: TC02
*** Objective
    The objective is to test if the Private DNS works as a Peer DNS.
*** Apparatus
    - The Private DNS container/machine
    - Another machine in the same network.
*** Theory
    The Private DNS should be able to resolve external domain names
    for the machine to be able to contact external sources. This is
    mainly required when we are updating the machine or trying to
    install any package. The mere presence of internet access is not
    sufficient. The machine requires the facility to be able to
    resolve hostnames as well.
*** Procedure
    - First we need to check the =/etc/resolv.conf= file in a machine
      which is a part of the same network as that of the Private DNS. 
    - The nameserver should be set as the IP of the Private DNS.
    - Now, in the machine we should be able to resolve the IP
      addresses of gnu.org or google.com using dig and nslookup.
      #+BEGIN_EXAMPLE
      nslookup gnu.org <Private DNS IP>
      #+END_EXAMPLE
      and
      #+BEGIN_EXAMPLE
      dig gnu.org @<Private DNS IP>
      #+END_EXAMPLE
*** Experiments
    - To test if we can resolve gnu.org using nslookup
    #+BEGIN_EXAMPLE
    nslookup gnu.org 10.100.1.5
    #+END_EXAMPLE
    - To test if we can resolve gnu.org using dig
    #+BEGIN_EXAMPLE
    dig gnu.org @10.100.1.5
    #+END_EXAMPLE
*** Result
    - The result for the first case with nslookup is as below:
    #+BEGIN_EXAMPLE
    Server:		10.100.1.5
    Address:	10.100.1.5#53

    Non-authoritative answer:
    Name:	gnu.org
    Address: 208.118.235.148
    #+END_EXAMPLE
    - The result of the first case with dig is as below:
    #+BEGIN_EXAMPLE
    ; <<>> DiG 9.8.2rc1-RedHat-9.8.2-0.30.rc1.el6_6.2 <<>> gnu.org @10.100.1.5
    ;; global options: +cmd
    ;; Got answer:
    ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 2113
    ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 4, ADDITIONAL: 7

    ;; OPT PSEUDOSECTION:
    ; EDNS: version: 0, flags:; udp: 4096
    ;; QUESTION SECTION:
    ;gnu.org.			IN	A

    ;; ANSWER SECTION:
    gnu.org.		158	IN	A	208.118.235.148

    ;; AUTHORITY SECTION:
    gnu.org.		158	IN	NS	ns4.gnu.org.
    gnu.org.		158	IN	NS	ns2.gnu.org.
    gnu.org.		158	IN	NS	ns1.gnu.org.
    gnu.org.		158	IN	NS	ns3.gnu.org.

    ;; ADDITIONAL SECTION:
    ns3.gnu.org.		86258	IN	A	46.43.37.70
    ns3.gnu.org.		86258	IN	AAAA	2001:41c8:20:2d3::a
    ns4.gnu.org.		158	IN	A	208.70.31.125
    ns2.gnu.org.		86258	IN	A	87.98.253.102
    ns1.gnu.org.		86258	IN	A	208.118.235.164
    ns1.gnu.org.		86258	IN	AAAA	2001:4830:134:3::f

    ;; Query time: 0 msec
    ;; SERVER: 10.4.12.160#53(10.4.12.160)
    ;; WHEN: Tue Apr 07 10:55:36 IST 2015
    ;; MSG SIZE  rcvd: 244
   #+END_EXAMPLE
*** Observation
    The results show that the Private DNS is being used to query the
    IP address of =gnu.org=. Nslookup shows us the IP of gnu.org. It
    also specifies that this reply is non authoritative. This is
    because our Private DNS server is not the authoritative server for
    gnu.org. The result from the dig command also shows the same
    inference. the dig command output shows that all the IPs of the
    authoritative servers of gnu.org.

*** Conclusion
    The Private DNS is able to resolve the public domain names as
    well.

* COMMENT Discussions
  In the introduction section:
  # Siva: I think private DNS does not resolve the external zones unless
  # we use forwarders(if i am wrong correct me), please check that.
  # Soumya: I dont think so. The recursion parameter is set for this
  # reason.
  
  In the functional requirements section:
  # siva: use some other word instead of "should". What about external
  # clients? \\ 
  # Soumya: External clients cannot in anyway connect to the
  # private DNS. I thought it is not needed to be explicitly mentioned.

  In structure of the scripts section:
  # Siva: write in separate paragraphs for each folder/file and we are
  # defining variables in templates, just declaring/using them. replace
  # "use" with "uses". These variables are may be defined in common_vars
  # or =vars/mail.yaml= file
  # Soumya: I feel it does not make much difference writing them in
  # different paragraphs. If i break them into paragraphs they will be
  # just single lines and does not look good.
