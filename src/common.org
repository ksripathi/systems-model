#+Title: Common Roles
#+Date: April 9, 2015. Thursday
#+PROPERTY: session *scratch*
#+PROPERTY: results output
#+PROPERTY: exports code
#+OPTIONS: ^:nil
\#+SETUPFILE: org-templates/level-0.org

* Introduction
  This document describes the requirements, design and implementation
  of the common role. Common role consists of basic functional and
  security requirements, which are applied on all the nodes in the
  cluster. Examples are given wherever possible. Test Cases are also
  described to test the setup.

  Cluster consists of many nodes. Every node has a specific purpose
  and its properties such as firewall rules and services are
  configured to serve the purpose. All the nodes are part of one
  cluster, they share some common properties in terms of system
  configuration. Some common system configuration is applied on all
  the nodes in the cluster. For example - packages such as
  =bind-utils=, =logwatch= are installed in all the systems and ssh
  root login is disabled in all the systems.

  For the better design and ease of administration processes a
  separate ansible role called "common" is created, which is run on
  all the nodes in cluster. It sets up the common parameters inside
  the system and also sets up the base for running individual roles.

* Requirements
  The functional and security requirements of the common role are mentioned here.

** Functional Requirements
   1) Set default gateway as router
   2) Save history of executed command with time stamp
   3) Start iptables service
   4) Permit root login without password
   5) Install bind utilities
   6) Remove sudoers package

** Security Requirements
   1) Secure server from various attacks such as brute-force
   2) Periodically mail summary of log files to the system administrator
   3) Disable password based ssh access
   4) Enable key based ssh authentication
   5) Do not permit empty password
   6) Lock root account

* Design
** System Design Diagram
   The following network diagram represents the interaction between the various
   nodes in the cluster.

   #+CAPTION:  Overall Cluster Network Diagram
   #+LABEL:  fig-overall-cluster-network-diagram
[[./diagrams/overall-cluster-network-diagram.png]]

** COMMENT Editable Link
[[https://docs.google.com/drawings/d/1-_1DAonwj9mfJYaXqHwZVHbzYEgDkzdTjOzDCBTpr-c/edit][   Google Drawing Link]]

** System Files
   The following table represents the description of the configuration
   files which are modified to setup the system.

|------+---------------+----------------------------------+----------------------------------|
| S.no | Service       | File                             | Description                      |
|------+---------------+----------------------------------+----------------------------------|
|   1. | iptables      | /etc/sysconfig/iptables          | iptables firewall start up rules |
|------+---------------+----------------------------------+----------------------------------|
|   2. | Fail2ban      | /etc/fail2ban/jail.local         | Configuration File               |
|------+---------------+----------------------------------+----------------------------------|
|   3. | History       | /etc/profile.d/history.sh        | Shell script                     |
|------+---------------+----------------------------------+----------------------------------|
|   4. | Local DNS     | /etc/hosts                       | Configuration File               |
|------+---------------+----------------------------------+----------------------------------|
|   5. | Logwatch      | /etc/logwatch/conf/logwatch.conf | Configuration File               |
|------+---------------+----------------------------------+----------------------------------|
|   6. | Sendmail      | /etc/mail/sendmail.mc            | Configuration File               |
|------+---------------+----------------------------------+----------------------------------|
|   7. | Name Resolver | /etc/resolv.conf                 | Configuration File               |
|------+---------------+----------------------------------+----------------------------------|
|   8. | SSH           | /etc/ssh/sshd_config             | Configuration File               |
|------+---------------+----------------------------------+----------------------------------|

* Implementation
** Structure of the scripts
   The implementation of this system is in terms of a collection of ansible
   scripts that configure the node. These scripts are organized in the following
   way:

#+BEGIN_EXAMPLE
|-code
|   |-- common.yml
|   |-- roles
|   |   |-- common
|   |   |   |-- files
|   |   |   |   `-- history.sh
|   |   |   |-- handlers
|   |   |   |   `-- main.yml
|   |   |   |-- meta
|   |   |   |   `-- main.yml
|   |   |   |-- tasks
|   |   |   |   `-- main.yml
|   |   |   |-- templates
|   |   |   |   `-- resolv.conf
|   |   |   |-- vars
|   |   |   |   `-- main.yml
#+END_EXAMPLE

Here =common.yml= file is a main playbook to configure nodes in the
cluster.

=roles/common/files/history.sh= file is a shell script to do the
history settings inside the system.

=roles/common/handlers/main.yml= file defines various handlers which
are only executed in case a task notifies them. Handlers are described
in details at [[Handlers][handlers]].  The handlers are called only when tasks are
called as part of the common role. Various templates and files are
being used during task execution for creating necessary configuration
files.

=roles/common/tasks/main.yml= file consist of various tasks which are
needed for setting up the nodes in the cluster. These tasks are
described [[Tasks][here]].

=roles/common/templates/resolv.conf= template file consist of
nameserver. This template uses various variables and these variable
values are defined in common_vars role.

=roles/common/vars/main.yml= file is the variables files which defines
the variables used by the ansible playbooks.

** Common Firewall Rules
   Firewall rules are set on all servers in the cluster. Each node has
   a specific set of rules depending upon the purpose of the
   node. However, some rules are common (intersection of firewall
   rules in all the server). These common rules are applied to all the
   servers in the cluster.

   The common firewall rules are described here. The description of
   rules, specific to the server are described in the individual
   server role's documentation.

*** Default rules for filter table
    Default policy for input, forward and output chain is set to
    "ACCEPT". Packets counters are set to [0:0]. First counter
    represents the number of packets that matched the rule for the
    chain, and the second counter represents the total size of the
    packets that matched the rule.

    #+BEGIN_EXAMPLE
    #If packet does not match any rule then the default action is applied to the packet
    *filter
    :INPUT ACCEPT [0:0]
    :FORWARD ACCEPT [0:0]
    :OUTPUT ACCEPT [0:0]
    #+END_EXAMPLE 

*** Rule for INPUT loopback packets
    Allow internal communication between services running within the
    system, over loopback interface. Destination IP is also specified
    to avoid any security breaches.

    #+BEGIN_EXAMPLE
    #Allow internal process to process communication over loopback interface
    -A INPUT -i lo -d 127.0.0.0/8 -j ACCEPT
    #+END_EXAMPLE
 
*** Rule for rate limiting new connections
    This rule limit all new connections except UDP connections. Limit
    is set to a proper high value, to secure the system from flooded
    connections. If system receives packets after the limit is
    exceeded then packets are dropped. Dropped packets are logged with
    a limited rate. Once the rate of incoming packets is under
    control, system again starts accepting the connections.

    #+BEGIN_EXAMPLE
    #Rate limit new connections to 20 new connections per 30 seconds
    -A INPUT ! -p udp -m state --state NEW -m recent --name new_limit --set
    -A INPUT ! -p udp -m state --state NEW -m recent --name new_limit --rcheck --seconds 30 --hitcount 20 -m limit --limit 2/min -j LOG --log-prefix "new_limit_"
    -A INPUT ! -p udp -m state --state NEW -m recent --name ssh_limit --rcheck --seconds 30 --hitcount 20 -j DROP
    #+END_EXAMPLE

*** Rule for incoming ping request with rate limiting
    Allow server to accept incoming ping requests from anywhere. To
    secure the system from flooded connections, limit is set to a
    proper high value. If system receives packets after the limit is
    exceeded then packets are dropped. Dropped packets are logged with
    a limited rate. Once the rate of incoming packets is under
    control, system again starts accepting the connections.

    #+BEGIN_EXAMPLE
    #Allow to accept incoming ping requests from anywhere
    -A INPUT -p icmp --icmp-type echo-request -m limit --limit 60/minute --limit-burst 120 -j ACCEPT
    -A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/minute --limit-burst 2 -j LOG 
    -A INPUT -p icmp --icmp-type echo-request -j DROP
    #+END_EXAMPLE

*** Rule for ongoing connection from other machine
    Allow server to continue already related and established
    connections. The connection get established only when firewall
    accepts the connection. If the connection got established, it
    would have passed through the firewall rules and later it is
    allowed to continue.

    #+BEGIN_EXAMPLE
    #Allow to continue already related and established connections
    -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
    #+END_EXAMPLE

*** Rule for incoming ssh connection
    Allow server to accept incoming ssh TCP port 22 connections *only*
    from the ansible, nagios and management ips. To add the same rule
    for multiple input IPs, a 'for loop' is defined in ansible
    template.

    #+BEGIN_EXAMPLE
    #Allowing incoming ssh connections only from the management ips. 
    #Hopefully fail2ban will take care of bruteforce attacks from management IPs
    {% for item in management_ips  %}  
    -A INPUT -m state --state NEW -s {{ item }} -p tcp -m tcp --dport 22 -j ACCEPT
    {% endfor %}
    #Allowing incoming ssh connections only from ansible server. 
    #Hopefully fail2ban will take care of bruteforce attacks from ansible server IPs
    {% for item in ansible_server_ips  %}
    -A INPUT -m state --state NEW -s {{ item }} -p tcp -m tcp --dport 22 -j ACCEPT
    {% endfor %}
    #Allow incoming SSH connections from nagios server IPs.  Hopefully fail2ban will take care of bruteforce attacks from ansible server IPs
    {% for item in nagios_server_ips  %}  
    -A INPUT -m state --state NEW -s {{item}} -p tcp -m tcp --dport 22 -j ACCEPT
    {% endfor %}
    #+END_EXAMPLE

*** Rule for incoming NRPE queries from Nagios server
    Accept NRPE queries on TCP port 5666 from Nagios node.

    #+BEGIN_EXAMPLE
    #Allow to accept incoming nrpe queries from nagios server
    -A INPUT -m state --state NEW -p tcp -m tcp --dport 5666 -j ACCEPT
    #+END_EXAMPLE
    
*** Rule for all other incoming connections
    Drop all the INPUT packets which does not match any of the defined
    rules. Dropped packets are logged with a limited rate.

    #+BEGIN_EXAMPLE
    #Log all other "blocked_input_" attempts with rate limiting
    -A INPUT -m state --state NEW -m limit --limit 2/min -j LOG --log-prefix "blocked_input_"
    #Drop all the INPUT packets which does not match any of the rules
    -A INPUT -j DROP
    #+END_EXAMPLE

*** Rule for FORWARD chain
    Forwarding rules are defined in the forward chain of the firewall.
    If the server does not forwards any packet the forwarding rule is
    set to "DROP" packets. If the server such as Router node forwards
    the connection then the rule is set to "ACCEPT" packets.
    
    #+BEGIN_EXAMPLE
    #Do not allow any packet to be forwarded.  Drop them silently without sending ICMP error messages back.
    -A FORWARD -j DROP
    #+END_EXAMPLE

*** Rule for OUTPUT loopback packets
    Allow internal communication between services running within the
    system, over loopback interface. Source ip is also specified to
    avoid any security breaches.

    #+BEGIN_EXAMPLE
    #Allow internal process to process communication over loopback interface
    -A OUTPUT -s 127.0.0.0/8 -o lo -j ACCEPT
    #+END_EXAMPLE
    
*** Rule for ongoing connection to other machine
    Allow server to continue already related and established
    connections. The connection get established only when firewall
    accepts the connection. If the connection got established, it
    would have passed through the firewall rules and later it is
    allowed to continue.
    
    #+BEGIN_EXAMPLE
    #Allow to continue already related and established connections
    -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
    #+END_EXAMPLE

*** Rule for allowing outgoing replies to ansible server from local SSH server
    For some reason state module does not works as intended on AWS VMs
    and hence during "=service iptables restart=" older ongoing
    connections are forgotten.  Thus when ansible does "service
    iptables restart" as part of common role the ansible server SSH
    connection itself is forgotten and is blocked by iptables after it
    restarts.  Therefore to allow ansible to restart iptables
    seamlessly following rules are required in all machines:

    #+BEGIN_EXAMPLE
    #Allow outgoing replies to ansible from SSH server
    {% for item in ansible_server_ips  %}
    -A OUTPUT -d {{item}} -p tcp -m tcp --sport 22 -j ACCEPT
    {% endfor %}
    #+END_EXAMPLE

*** Rule for outgoing dns request
    Allow server to make dns queries.

    #+BEGIN_EXAMPLE
    #Allow to make dns queries
    -A OUTPUT -p udp -m udp --dport 53 -j ACCEPT
    #+END_EXAMPLE

*** Rule for sending log messages to rsyslog server
    Allow server to send log messages to rsyslog server.

    #+BEGIN_EXAMPLE
    #Allow server to send log messages to rsyslog server
    -A OUTPUT -p udp -m udp --dport 514 -j ACCEPT
    #+END_EXAMPLE

*** Rule for sending mails by logwatch service
    Allow logwatch service running inside the server to send mail
    alerts.

    #+BEGIN_EXAMPLE
    #Allow to send mails by logwatch service
    -A OUTPUT -p tcp -m tcp --dport 25 -j ACCEPT
    #+END_EXAMPLE

*** Rule for outgoing web request by yum
    Allow yum service to update packages via http and https. 

    #+BEGIN_EXAMPLE
    #Allow yum to contact web servers for installing and updating packages
    -A OUTPUT -p tcp -m tcp --dport 80 -j ACCEPT
    -A OUTPUT -p tcp -m tcp --dport 443 -j ACCEPT
    #+END_EXAMPLE

*** Rule for outgoing connection to OSSEC server
    Allow server to send system's information to OSSEC server.

    #+BEGIN_EXAMPLE
    #Allow outgoing connections to OSSEC server
    -A OUTPUT -p udp -m udp --dport 1514 -j ACCEPT
    #+END_EXAMPLE
    
*** Rule for outgoing ping request
    Allow server to send ping requests to anywhere.

    #+BEGIN_EXAMPLE
    #Allow to send ping requests to anywhere.
    -A OUTPUT -p icmp --icmp-type echo-request -j ACCEPT
    #+END_EXAMPLE

*** Rule for all other outgoing packets
    Reject all the OUTPUT packets which does not match any of the
    defined firewall rules with a reply message =icmp-host-prohibited=
    to the host machine. Rejected packets are also logged with a
    limited rate.

    #+BEGIN_EXAMPLE
    #Log all other "blocked_output_" attempts
    -A OUTPUT -m state --state NEW -m limit --limit 2/min -j LOG --log-prefix "blocked_output_"
    #Reject all the OUTPUT packets which does not match any of the rules
    -A OUTPUT -j REJECT --reject-with icmp-host-prohibited
    #+END_EXAMPLE

*** Enforce filter rules
    #+BEGIN_EXAMPLE
    COMMIT
    #+END_EXAMPLE
** Tasks
*** Configure Hostname
   Hostname is set inside each node in the cluster. Hostname represent
   the name of the main server that is installed in the node.
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
---

#This will use the variables defined in the role sepcific yaml file, works only on CentOS
- name: Set the hostname of the target if host_name is defined
  lineinfile: dest=/etc/sysconfig/network regexp="HOSTNAME=" line="HOSTNAME={{host_name}}" state=present
  when: host_name is defined

- name: Set the hostname using hostname command
  hostname: name={{host_name}}
  when: host_name is defined
#+END_SRC

*** Set Default Gateway
   In the cluster only two nodes - Router node and Ansible node, are
   part of both public and the private network. Gateway of these two
   nodes are set by the dhcp server, and these nodes have direct
   internet access.

   All the other nodes in the cluster are only part of the private
   network. These nodes do not have direct internet access. These
   nodes get internet by forwarding requests to the router node, then
   the router does the required packet management to get internet for
   these nodes. Router node acts as a gateway for all the private
   servers.

   To configure default gateway for private servers following actions
   are performed:
   1) Remove any default gateway if set already.
   2) Set default gateway as Router.

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: setting the default gw, skips if router or ansible server
  shell: route del default; route add default gw {{router_internal_ip}}
  when: not ( i_ans is defined or i_router is defined )
  ignore_errors: yes
#+END_SRC

*** Block Malicious Attacks
   Nodes in the cluster are protected against Brute-force attacks. For
   this *Fail2ban* service is configured on all the nodes. It bans an
   offensive host by adding rule in firewall and also sends an email
   alerts to the system administrator. When the firewall rule for
   offensive host is added, the attacker can not connect to the
   cluster for a limited period of time.

   To configure Fail2ban following actions are performed:
   1) Install epel repo
   2) Install fail2ban
   3) Start fail2ban service

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: Install epel RPM
  yum: name=epel-release state=present
  environment: proxy_env

#Install fail2ban and enable it on startup
- name: Install fail2ban
  yum: name=fail2ban state=present

- name: Start and enable fail2ban service
  service: name=fail2ban state=started enabled=yes
#+END_SRC

*** Save History of Executed Commands
   Commands executed on the servers are logged with the time
   stamp. These logged commands can be referred by the system
   administrator to trouble shoot any issues on the server.

   To save history of commands a shell script is created and placed
   inside =/etc/profile.d= directory. Scripts present inside the
   =/etc/profile.d= directory gets executed at the start of every new
   session.

   Following history parameters are set:

    - HISTTIMEFORMAT :: sets the time format of time stamp
    - HISTSIZE       :: sets the number of lines or commands that are
                        stored in memory in a history list while bash
                        session is ongoing
    - HISTFILESIZE   :: sets the number of lines or commands that are allowed in
                        the history file at start up time of a session, and are
                        stored in the history file at the end of bash session
                        for use in future sessions.

#+BEGIN_SRC shell :tangle roles/common/files/history.sh
#!/bin/bash

HISTTIMEFORMAT="%y %m %d %T"
HISTSIZE=100000
HISTFILESIZE=100000
export HISTTIMEFORMAT HISTSIZE HISTFILESIZE
#+END_SRC 

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: For below task to run it requires libselinux-python to be installed
  yum: name=libselinux-python state=present
#Configure history
- name: Configure history for all users with date/time and 100,000 lines of history
  copy: src=history.sh dest=/etc/profile.d/history.sh mode=755 owner=root group=root
#+END_SRC 

*** Start iptables service
   While setting up the cluster, iptables service is restarted on all
   the servers - to make sure the service is running inside each
   server. If anyone inserts a temporary or adhoc rule using terminal
   commands such as =iptables -A INPUT -p tcp --dport 80 -j ACCEPT=,
   the rules will not be saved in the file. These rules we assume are
   not necessary for the system, so restarting "iptables" will remove
   these inserted rules.

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
#Restart iptables
- name: Restart iptables service 
#checking whether iptables is running is pointless
#restart would fail if there is no /etc/sysconfig/iptables file
  service: name=iptables state=restarted
  ignore_errors: yes
#+END_SRC

*** Setup /etc/hosts file
   Sendmail tries to lookup hostname and IP mapping through
   =/etc/hosts=. Sendmail assumes the first line in =/etc/hosts= is
   the nodes own FQDN to IP mapping without this sendmail takes about
   30 seconds to timeout for host resolution. To take care of this
   assumption of sendmail =/etc/hosts= file is configured.

   Following variables are set by the ansible playbook scripts as it
   runs on the client node. For each server in the cluster value of
   these variables will be different and set according to the server
   role.

|-------+------------------------------+-------------------------------+--------------------------|
| S.no. | Variable Name                | Description                   | Example                  |
|-------+------------------------------+-------------------------------+--------------------------|
|    1. | ansible_default_ipv4.address | defines the system ip address | 10.1.100.8               |
|-------+------------------------------+-------------------------------+--------------------------|
|    2. | ansible_fqdn                 | define the system fqdn        | ossec.virtual-labs.ac.in |
|-------+------------------------------+-------------------------------+--------------------------|
|    3. | ansible_hostname             | defines the system hostnames  | ossec                    |
|-------+------------------------------+-------------------------------+--------------------------|

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
#Setup /etc/hosts
- name: Configure hostname and fqdn to resolve to local IP on first line of /etc/hosts
#Necessary for containers so that they can send emails without 30 second delay
  lineinfile: dest=/etc/hosts regexp="{{ansible_default_ipv4.address}} {{ansible_fqdn}} {{ansible_hostname}}" insertbefore="BOF" line="{{ansible_default_ipv4.address}} {{ansible_fqdn}} {{ansible_hostname}}"
#+END_SRC

*** setup aliases

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
#Setup /etc/aliases
- name: Configure aliases in /etc/aliases
#Necessary for containers so that they can send emails to alerts@vlabs.ac.in
  lineinfile: dest=/etc/aliases regexp="^root:*" line="root":" alerts@vlabs.ac.in"
- name: update aliases database by running newaliases
  shell: newaliases
  notify:
   - restart sendmail
#+END_SRC

*** Install vim
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
#Necessary for containers as a editor
- name: installing vim
  yum: name=vim state=present
#+END_SRC

*** Summary of Log files
   Servers and applications create "log files" to keep track of the
   events happening inside the system at any given time. These log
   files are used for analysis of the system.

   To generate a unified report of all log files and send to system
   administrator *Logwatch* service is configured on all the servers
   in the cluster.

   To configure logwatch following actions are performed:
   1) Install "logwatch" tool
   2) Set detail of log level to "medium"

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
#Logwatch configuration
- name: Install logwatch
  yum: name=logwatch state=installed
  environment: proxy_env

- name: Configure detailed logging via logwatch
  lineinfile: line="Detail = High" dest=/etc/logwatch/conf/logwatch.conf regexp="^Detail ="  
#+END_SRC

*** Configure mail service
   Sendmail service is configured on all the servers in the
   cluster. Services such as "logwatch" uses "sendmail" service to
   send mail alerts to the system administrator.

   To configure sendmail following actions are performed:
   1) Install sendmail
   2) Ensure postfix is stopped and disabled
   3) Set smtp smart host
   4) Start sendmail service

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
#SMTP configuration
- name: Install sendmail SMTP server for outgoing email
  yum: name=sendmail state=installed
  environment: proxy_env

- name: Ensure that postfix is stopped and disabled
  service: name=postfix enabled=no state=stopped
#if postfix is not present ignore error
  ignore_errors: yes

- name: Configure SMART_HOST if necessary
  lineinfile: line="define(`SMART_HOST', `{{smtp_smart_host}}')dnl" regexp="SMART_HOST" dest="/etc/mail/sendmail.mc"
  when: smtp_smart_host != "none"
  notify:
    - restart sendmail

- name: Ensure that sendmail is running and enabled
  service: name=sendmail enabled=yes state=started
#+END_SRC

*** Set Name Resolver
   Nameservers are set on all the servers in the cluster. An example
   of configuration file - =/etc/resolv.conf= is shown and described
   below:

#+BEGIN_EXAMPLE
search localdomain.com
nameserver 10.4.12.230
#+END_EXAMPLE

   - search :: This field allows users to type simple names instead of
               complete 'fqdn' to reach local resources. If something
               comes to resolver that has no dots '.' in it, the
               resolver will try adding =localdomain.com= in it.
   - nameserver :: This field specifies the ip address of the dns
                   servers.

   Ansible jinja2 template is copied to the all nodes from the
   configuration server node.

#+BEGIN_SRC conf :tangle roles/common/templates/resolv.conf
{% if private_dns_zone != "none" %}
search {{private_dns_zone}}
{% endif %}
{% for private_dns in private_dns_ips %}
nameserver {{private_dns}}
{% endfor %}
#+END_SRC

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
#Configure private DNS if values are set 
- name: Configure node to use private DNS (peerDNS)
  template: src=resolv.conf dest=/etc/resolv.conf owner=root group=root mode=644
  when: private_dns_ips != "none" 
  tags:
    - setup_private_dns
#+END_SRC

*** COMMENT SSH Hardening
   All the servers in the cluster are made secure by hardening *ssh*
   service. SSH configuration file =/etc/ssh/sshd_config= is
   customized as per the requirement.

**** Permit Root Login without password
   Only system administrators with ssh private key can login as Root.

#+BEGIN_EXAMPLE
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: Permit root login without-password(key based)
  lineinfile: dest=/etc/ssh/sshd_config regexp='PermitRootLogin ' line='PermitRootLogin without-password' state=present
#+END_SRC
#+END_EXAMPLE

**** Disable Password based access
   Password based access is disabled.
#+BEGIN_EXAMPLE
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: Disable Password authentication
  lineinfile: dest=/etc/ssh/sshd_config regexp='PasswordAuthentication ' line='PasswordAuthentication no'
#+END_SRC
#+END_EXAMPLE

**** Enable Key based authentication
   Only key based access is enabled.
#+BEGIN_EXAMPLE
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: Enable Public key authentication
  lineinfile: dest=/etc/ssh/sshd_config regexp='PubkeyAuthentication ' line='PubkeyAuthentication yes'
#+END_SRC
#+END_EXAMPLE

**** Do not permit empty passwords
   Users are not allowed to set empty-password.
#+BEGIN_EXAMPLE
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: Do not permit empty password, also ensure proper owner, group and permissions
  lineinfile: dest=/etc/ssh/sshd_config regexp='PermitEmptyPasswords ' line='PermitEmptyPasswords no' mode=0600 owner=root group=root

#Call handler to restart sshd
  notify:
      - restart sshd
#+END_SRC
#+END_EXAMPLE

*** COMMENT Install Bind Utilities
   Bind utilities are installed on all the servers in the cluster. This package
   includes programs such as *nslookup*, *dig* and *host*. These utilities are
   used by system administrators to trouble shoot the network related issues.

#+BEGIN_EXAMPLE
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: install bind-utils
  yum: name=bind-utils state=present
  environment:
   proxy_env
#+END_SRC
#+END_EXAMPLE

*** COMMENT Disable Root Login
   Root login is disabled on all the servers in the cluster. Password
   for the root account is set to a value which matches no possible
   encrypted value, therefore nobody can login as root with
   password. Only system administrators with ssh private keys can
   login to root account.

**** Lock root login
   Root account is locked using =passwd= command command in the
   terminal.  Another way to lock account is to replace the root's
   encrypted password with '!' in =/etc/shadow= file as follows.

#+BEGIN_EXAMPLE
root:!:12345::::::
#+END_EXAMPLE

#+BEGIN_EXAMPLE
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: lock root account
  shell: passwd -l root
#+END_SRC
#+END_EXAMPLE

**** Enable root login
   Root login can be enabled by setting the root password using
   following command
#+BEGIN_EXAMPLE
sudo passwd root
#+END_EXAMPLE

**** Unlock root account
   Root login can be unlocked using following command.
#+BEGIN_EXAMPLE
sudo passwd -u root
#+END_EXAMPLE

*** COMMENT Remove sudoers package
   We can do two things with sudoers package. The current scripts
   perhaps does remove it, but we can always rewrite them.

**** Why Remove ?
   Sudoers package is removed from all the servers in the
   cluster. There are no user account created on the server. Only the
   system administrator login as root user. There is no need of
   maintaining sudoers file. Removing this package causes no harm to
   the system.

**** Ensure that validity of sudoers file
   Ensure that =/etc/sudoers= file is same as it is during
   installation and no one has added new users or groups to sudoers,
   as backdoors to gain root access.

#+BEGIN_EXAMPLE
#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: remove sudo
  yum: name=sudo state=absent
#+END_SRC
#+END_EXAMPLE

*** Set the implementation/model release
   Release number is set in all the nodes in the cluster. Release
   number describes the version of the configuration applied on the
   node.

#+BEGIN_SRC yml :tangle roles/common/tasks/main.yml
- name: setting the implementation/model release
  lineinfile: dest=/etc/motd regexp="^Release" line="Release number {{ release_no }}" state=present create=yes
  ignore_errors: yes
#+END_SRC

*** Common Variables
   Variables which are common across all the ansible roles are defined
   in =common_vars= file. The file is included as a dependency for
   this role.

#+BEGIN_SRC yml :tangle roles/common/meta/main.yml
---
dependencies:
  - role: common_vars
#+END_SRC

** Handlers
   When any changes are made in the configuration file of any service, the
   service needs to be restarted. For example, if modifications are made in
   sendmail configuration file to customize sendmail service, then the sendmail
   service needs to be restarted to enforce the modified properties of the
   system.

#+BEGIN_SRC yml :tangle roles/common/handlers/main.yml
---
- name: restart sendmail
  service: name=sendmail state=restarted
#+END_SRC
    
* Test Cases
** Test Case-1: Check Bind utilities are installed
*** Objective
   To check bind-utilities are installed on the system.
*** Apparatus
   1) An instance of common role - a common server

*** Experiment
**** Execute nslookup command
#+BEGIN_EXAMPLE
nslookup localhost
#+END_EXAMPLE

**** Execute host command
#+BEGIN_EXAMPLE
host localhost
#+END_EXAMPLE

**** Execute dig command
#+BEGIN_EXAMPLE
dig localhost
#+END_EXAMPLE

*** Result
**** Sample output of step-1 of experiment.
#+BEGIN_EXAMPLE
Server:		10.100.1.5
Address:	10.100.1.5#53

Name:	localhost
Address: 127.0.0.1
#+END_EXAMPLE

**** Sample output of step-2 of experiment.
#+BEGIN_EXAMPLE
localhost has address 127.0.0.1
localhost has IPv6 address ::1
#+END_EXAMPLE

**** Sample output of step-3 of experiment.
#+BEGIN_EXAMPLE

; <<>> DiG 9.8.2rc1-RedHat-9.8.2-0.30.rc1.el6_6.2 <<>> localhost
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 13553
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 1

;; QUESTION SECTION:
;localhost.			IN	A

;; ANSWER SECTION:
localhost.		86400	IN	A	127.0.0.1

;; AUTHORITY SECTION:
localhost.		86400	IN	NS	localhost.

;; ADDITIONAL SECTION:
localhost.		86400	IN	AAAA	::1

;; Query time: 0 msec
;; SERVER: 10.100.1.5#53(10.100.1.5)
;; WHEN: Mon Apr 13 05:45:12 2015
;; MSG SIZE  rcvd: 85

#+END_EXAMPLE

*** Observation
   *dig*, *nslookup* and *host* commands are executed on the server,
   and proper output is displayed.

*** Conclusion
   Bind-utilities are installed on all the servers in the cluster.

** Test Case-2: SSH access
*** Objective
   Test ssh access is allowed only from ansible, nagios and management
   ips.

*** Apparatus
   1) Configuration server
   2) A management server
   3) A nagios server
   4) An instance of common role - a common server
   5) Any other machine in the same network

*** Experiment
   Servers in which common firewall rules are applied accept ssh
   connection on TCP port 22 only from the ansible, nagios and
   management ips.

**** SSH from configuration server to a common server
#+BEGIN_EXAMPLE
ssh root@<common-server-ip>
#+END_EXAMPLE

**** SSH from management server to a common server
#+BEGIN_EXAMPLE
ssh root@<common-server-ip>
#+END_EXAMPLE

**** SSH from nagios server to a common server
#+BEGIN_EXAMPLE
ssh root@<common-server-ip>
#+END_EXAMPLE

**** SSH from any other machine to a common server
#+BEGIN_EXAMPLE
ssh root@<common-server-ip>
#+END_EXAMPLE
*** Result
**** Output of step-1 of experiment
#+BEGIN_EXAMPLE
Last login: Thu Apr  2 ... other details.....
root@common-server:~#
#+END_EXAMPLE
**** Output of step-2 of experiment
#+BEGIN_EXAMPLE
Last login: Thu Apr  2 ... other details.....
root@common-server:~#
#+END_EXAMPLE

**** Output of step-3 of experiment
#+BEGIN_EXAMPLE
Last login: Thu Apr  2 ... other details.....
root@common-server:~#
#+END_EXAMPLE

**** Output of step-4 of experiment
#+BEGIN_EXAMPLE
Permission Denied ....
#+END_EXAMPLE

*** Observation
   A common server accepts incoming ssh connections from
   configuration, nagios and management server.

*** Conclusion
   Firewall rules are set properly to allow ssh connection only from
   ansible, nagios and management server.

** Test Case-3: Root account is locked
*** Objective
   Test root account is locked in a common server.
*** Apparatus
   1) Configuration server
   2) An instance of common role - a common server

*** Experiment
   Execute following command on the server.

#+BEGIN_EXAMPLE
sudo passwd -S root
#+END_EXAMPLE

*** Result
   Output of step-1 signifies the root account is locked.

#+BEGIN_EXAMPLE
root LK 2012-10-07 0 99999 7 -1 (Password locked.)
#+END_EXAMPLE

*** Observation
   Root account is disabled.

*** Conclusion
   Users can not login to the server as 'root' username with password.

** Test Case-4: Check default gateway is set
*** Objective
   To check the default gateway of all the private servers are set to
   router node.
*** Apparatus
   1) An instance of common role - a common server

*** Experiment
   Check routing table by executing following command in the terminal.

#+BEGIN_EXAMPLE
route -n
#+END_EXAMPLE

*** Result
   Sample output of step-1 of experiment is shown below. Last entry in
   the routing table, shows that the gateway for all the traffic is
   set to =10.100.1.1= which is router's internal ip.

#+BEGIN_EXAMPLE
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
10.100.0.0      0.0.0.0         255.255.252.0   U     0      0        0 eth0
169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth0
0.0.0.0         10.100.1.1      0.0.0.0         UG    0      0        0 eth0
#+END_EXAMPLE

*** Observation
   Gateway for all the private servers in the cluster is set to the
   router.

*** Conclusion
   Gateway for all the private servers in the cluster is set to the
   router.

** Test Case-5: Check blocking of malicious attacks
*** Objective
   To check fail2ban service bans offensive users when malicious
   attacks are done.
*** Apparatus
   1) An instance of common role - a common server
   2) Any other server in the same network

*** Experiment
**** Check fail2ban service is running
#+BEGIN_EXAMPLE
service fail2ban status
#+END_EXAMPLE

**** SSH to the server 
   SSH to the server from any other node by intentionally giving wrong
   passwords. Do this at least three times. Then on the server execute
   the following command to check if fail2ban filter for ssh detects
   failed login attempts.

#+BEGIN_EXAMPLE
fail2ban-regex /var/log/secure /etc/fail2ban/filter.d/sshd.conf <username|ipaddress>
#+END_EXAMPLE 

**** Check firewall rule
   Check if there is any firewall rule for fail2ban-ssh is added to
   block the machine's ip from where multiple failed login attempts
   are made.

#+BEGIN_EXAMPLE
iptables --list
#+END_EXAMPLE

*** Result
**** Output of step-1 of experiment.
#+BEGIN_EXAMPLE
fail2ban-server (pid  1010) is running...
Status
|- Number of jail:	1
`- Jail list:		ssh-iptables
#+END_EXAMPLE

**** Output of step-2 of experiment
   It shows that there are failed login attempts were made to the
   ossec-server from "10.100.1.2" ipaddress.

#+BEGIN_EXAMPLE
Running tests
=============

Use ignoreregex line : 10.100.1.2
Use   failregex file : /etc/fail2ban/filter.d/sshd.conf
Use         log file : /var/log/secure


Results
=======

Failregex: 0 total

Ignoreregex: 7 total
|-  #) [# of hits] regular expression
|   1) [7] 10.100.1.2
`-

Date template hits:
|- [# of hits] date format
|  [166] MONTH Day Hour:Minute:Second
`-

Lines: 166 lines, 7 ignored, 0 matched, 159 missed
|- Ignored line(s):
|  Apr 13 05:53:10 ossec-server sshd[10473]: Invalid user test from 10.100.1.2
|  Apr 13 05:53:12 ossec-server sshd[10473]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=10.100.1.2
|  Apr 13 05:53:14 ossec-server sshd[10473]: Failed password for invalid user test from 10.100.1.2 port 38428 ssh2
|  Apr 13 05:53:14 ossec-server sshd[10473]: Failed password for invalid user test from 10.100.1.2 port 38428 ssh2
|  Apr 13 05:53:15 ossec-server sshd[10473]: Failed password for invalid user test from 10.100.1.2 port 38428 ssh2
|  Apr 13 05:53:15 ossec-server sshd[10474]: Connection closed by 10.100.1.2
|  Apr 13 05:53:16 ossec-server sshd[10475]: Invalid user test from 10.100.1.2
`-
Missed line(s): too many to print.  Use --print-all-missed to print all 159 lines
#+END_EXAMPLE

**** Output of step-3 of experiment
   Output shows that fail2ban-ssh chain is now defined on the server,
   to reject all the incoming ssh connections from the malicious
   ipaddress.

#+BEGIN_EXAMPLE
Chain fail2ban-SSH (1 references)
target     prot opt source               destination         
REJECT     all  --  10.100.1.2           anywhere            reject-with icmp-port-unreachable 
RETURN     all  --  anywhere             anywhere            
#+END_EXAMPLE

*** Observation
   *Fail2ban* service detects malicious attacks.

*** Conclusion
   *Fail2ban* service detects malicious attacks.

** Test Case-6: Check Command History is getting saved
*** Objective
   To check whether the commands executed on the server are getting
   logged with proper time stamp.
*** Apparatus
   1) An instance of common role - a common server

*** Experiment
**** Execute following example sequence of commands on the server
#+BEGIN_EXAMPLE
[root@common-server ~]$ ls
/root
[root@common-server ~]$ pwd
[root@common-server ~]$ echo $PATH
/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin
[root@common-server ~]$ ssh root@router.vlabs.ac.in
ssh: connect to host router.vlabs.ac.in port 22: Connection refused
#+END_EXAMPLE
   Now execute history commands to see whether the commands are
   getting saved with proper time stamp.
#+BEGIN_EXAMPLE
[root@common-server ~]$ history
#+END_EXAMPLE

*** Result
   Output of step-1 of experiment.

#+BEGIN_EXAMPLE
   21  15 04 13 10:27:45ls
   22  15 04 13 10:27:46pwd
   23  15 04 13 10:27:54echo $PATH
   24  15 04 13 10:28:17ssh root@router.vlabs.ac.in
   25  15 04 13 10:28:22history
#+END_EXAMPLE
*** Observation
   History of commands are getting saved with proper time stamp.

*** Conclusion
   History of commands are getting saved with proper time stamp.

** Test Case-7: Check Sendmail is sending mail
*** Objective
   Test sendmail service is able to send mails to the system
   administrator. The sendmail service is used by various other
   services such as logwatch and fail2ban.
*** Apparatus
   1) An instance of common role - a common server

*** Experiment
**** Send mail to an email-id using following command
#+BEGIN_EXAMPLE
mail <email-address>
Subject: test
Test
EOT
#+END_EXAMPLE

**** Check the mail client if any mail is received from the server
*** Result
   Sample mail of step-2 of experiment may look like as follows:

#+BEGIN_EXAMPLE
from:	root <root@common-server.virtual-labs.ac.in>
to:	sysadmin@vlabs.ac.in
date:	Mon, Apr 13, 2015 at 3:03 PM
subject:	test

test
#+END_EXAMPLE

*** Observation
   An email is received from the server via sendmail service.

*** Conclusion
   Sendmail is configured properly and is able to send mail.

** Test Case-8: Check nameservers are set
*** Objective
   To check nameserver is set on the server for name resolution.

*** Apparatus
   1) An instance of common role - a common server

*** Experiment
**** Check content of =/etc/resolv.conf= file.
#+BEGIN_EXAMPLE
cat /etc/resolv.conf
#+END_EXAMPLE

**** Do a dig query for google.com, using nameserver mentioned in =/etc/resolv.conf= file.
#+BEGIN_EXAMPLE
dig google.com @<nameserver-ip>
#+END_EXAMPLE

*** Result
**** Sample output of step-1 of experiment.
#+BEGIN_EXAMPLE
search base1.virtual-labs.ac.in base1.vlabs.ac.in
nameserver 10.100.1.5
#+END_EXAMPLE

**** Sample output of step-2 of experiment.
#+BEGIN_EXAMPLE
; <<>> DiG 9.8.2rc1-RedHat-9.8.2-0.30.rc1.el6_6.2 <<>> google.com @10.100.1.5
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 1314
;; flags: qr rd ra; QUERY: 1, ANSWER: 11, AUTHORITY: 4, ADDITIONAL: 4

;; QUESTION SECTION:
;google.com.			IN	A

;; ANSWER SECTION:
google.com.		300	IN	A	173.194.36.105
google.com.		300	IN	A	173.194.36.100
google.com.		300	IN	A	173.194.36.102
google.com.		300	IN	A	173.194.36.103
google.com.		300	IN	A	173.194.36.99
google.com.		300	IN	A	173.194.36.110
google.com.		300	IN	A	173.194.36.96
google.com.		300	IN	A	173.194.36.101
google.com.		300	IN	A	173.194.36.104
google.com.		300	IN	A	173.194.36.97
google.com.		300	IN	A	173.194.36.98

;; AUTHORITY SECTION:
google.com.		172800	IN	NS	ns2.google.com.
google.com.		172800	IN	NS	ns3.google.com.
google.com.		172800	IN	NS	ns1.google.com.
google.com.		172800	IN	NS	ns4.google.com.

;; ADDITIONAL SECTION:
ns2.google.com.		172800	IN	A	216.239.34.10
ns1.google.com.		172800	IN	A	216.239.32.10
ns3.google.com.		172800	IN	A	216.239.36.10
ns4.google.com.		172800	IN	A	216.239.38.10

;; Query time: 287 msec
;; SERVER: 10.100.1.5#53(10.100.1.5)
;; WHEN: Mon Apr 13 06:08:15 2015
;; MSG SIZE  rcvd: 340
#+END_EXAMPLE

*** Observation
   Server is able to resolve the names using the given nameservers.

*** Conclusion
   Nameservers are properly set on all the servers in the cluster.
** Test Case-9: Check empty passwords are not permitted
*** Objective
   Test that the users can not login to the server with empty password.

*** Apparatus
   1) An instance of common role - a common server

*** Experiment
   Login to the server with following command

#+BEGIN_EXAMPLE
ssh root@<common-server-ip>
#+END_EXAMPLE
*** Result
   Output of step-1 of experiment is shown below.

#+BEGIN_EXAMPLE
Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).
#+END_EXAMPLE

*** Observation
   When a user tries to login to the server with empty password and
   without ssh keys, the server denies the access.

*** Conclusion
   Users are not allowed access to the server with empty. Only
   administrators with private ssh keys can login to the server.

** Test Case-10: Password based access is disabled
*** Objective
   To test that the password access is disabled on all the servers in the cluster.

*** Apparatus
   1) An instance of common role - a common server
   2) Any other machine

*** Experiment
   Login to the common server from any other machine using following
   command:

#+BEGIN_EXAMPLE
ssh <username>@<common-server-ip>
#+END_EXAMPLE

*** Result
   Sample output of step-1 of experiment is shown below.

#+BEGIN_EXAMPLE
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
#+END_EXAMPLE

*** Observation
   When a user tries to login to the server with password and without
   ssh keys, the server denies the access.

*** Conclusion
   Users are not allowed password based access. Only administrators
   with private ssh keys can login to the server.

** Test Case-11: Test sudoers package is removed
*** Objective
   To test the sudoers package is removed from the server.
*** Apparatus
   1) An instance of common role - a common server

*** Experiment
   Execute a command with sudo, for example

#+BEGIN_EXAMPLE
sudo su -
sudo ls
#+END_EXAMPLE

*** Result
   Sample output of step-1 of experiment.

#+BEGIN_EXAMPLE
-bash: sudo: command not found
#+END_EXAMPLE
*** Observation
   If sudoers package is removed from the server, users can not
   execute command with sudo privileges.
*** Conclusion
   Sudoers package is removed from all the servers in the cluster.



